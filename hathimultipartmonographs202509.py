# -*- coding: utf-8 -*-
"""HathiMultipartMonographs202509.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yUPLu1Db2M4-hoe-bsBDgBvimMNzA4CJ
"""

import pandas as pd

from google.colab import drive

drive.mount('/content/drive/')

drive.mount("/content/drive/", force_remount=True)

!ls

import sqlite3

conn = sqlite3.connect("HathiMultipartMonos2025.db")

cursor = conn.cursor()

cursor.execute("DROP TABLE IF EXISTS HathiMultipartMonos2025")

pip install pymarc

import csv

csv_out = csv.writer(open('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MultipartMonoProtoBibsHurry.csv', 'w'), delimiter = ',', quotechar = '"', quoting = csv.QUOTE_MINIMAL)

from pymarc import MARCReader, Field, Subfield

with open('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MARCPrint202508.mrc', 'rb') as fh:
    reader = MARCReader(fh)
    for record in reader:
      csv_record = {}
      try:
        OCN = record['001']
        OCN = str(OCN).replace('=001', '')
        csv_record[OCN] = OCN
        LDR06 = record.leader[6]
        csv_record[LDR06] = LDR06
        LDR07 = record.leader[7]
        csv_record[LDR07] = LDR07
        for field in record.get_fields('008'):
          field008data = field.value()
        field00823 = field008data[23]
        field00828 = field008data[28]
        field00829 = field008data[29]
        title = (record['245']['a'])
        csv_record[title] = title
        field040d = record['040'].get_subfields('d')
        field040d = str(field040d)
        csv_record[field040d] = field040d
        field533s = record.get_fields('533')
        if not field533s:
          field533list = []
          field533list.append(str("No field 533"))
        else:
          field533list = []
          for i in field533s:
            for subfield in i:
              if subfield.code == 'a':
                field533list.append(str(subfield.value))
              else:
                pass
        csv_out.writerow([OCN, LDR06, LDR07, field00823, field00828, field00829, field040d, title, field533list])
      except KeyError:
            pass

colnames = ['OCN', 'LDR06', 'LDR07', 'field00823', 'field00828', 'field00829', 'field040d', 'title', 'field533']
Bibs = pd.read_csv('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MultipartMonoProtoBibs.csv', names=colnames, low_memory=False)
column_headers = list(Bibs.columns.values)
print(column_headers)
Bibs = Bibs.astype(str)
Bibs['OCN'] = Bibs['OCN'].astype(str)
Bibs['OCN'] = Bibs['OCN'].str.strip()
Bibs['OCN'] = Bibs['OCN'].str.lstrip('0')

len(Bibs)

Bibs.sample(5)

import csv

csv_out = csv.writer(open('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MultipartMonoProtoLHRsHurry.csv', 'w'), delimiter = ',', quotechar = '"', quoting = csv.QUOTE_MINIMAL)

from pymarc import MARCReader, Field, Subfield

with open('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MARCPrint202508.mrc', 'rb') as fh:
    reader = MARCReader(fh)
    for record in reader:
      csv_record = {}
      try:
        LCN = record['001']
        LCN = str(LCN).replace('=001', '')
        csv_record[LCN] = LCN
        LDR06 = record.leader[6]
        csv_record[LDR06] = LDR06
        LOCN = record['004']
        LOCN = str(LOCN).replace('=004 ', '')
        csv_record[LOCN] = LOCN
        BranchName = (record['852']['b'])
        if not BranchName:
          csv_record[BranchName] = str("No Branch Name")
        else:
          csv_record[BranchName] = str(BranchName)
        Location = (record['852']['c'])
        if not Location:
          csv_record[Location] = str("No Location")
        else:
          csv_record[Location] = str(Location)
        Field863s = record.get_fields('863')
        Field863list = []
        if not Field863s:
          Field863list.append(str("No Field 863"))
        else:
          for Field863 in Field863s:
            field863a = Field863.get_subfields('a')
            if not field863a:
              Field863list.append(str("No Field 863a"))
            else:
              for i in field863a:
                Field863list.append(str(i))
        Field866s = record.get_fields('866')
        Field866list = []
        if not Field866s:
          Field866list.append(str("No Field 866"))
        else:
          for Field866 in Field866s:
            field866a = Field866.get_subfields('a')
            if not field866a:
              Field866list.append(str("No Field 866a"))
            else:
              for i in field866a:
                Field866list.append(str(i))
        Field876s = record.get_fields('876')
        EnumChronList = []
        if not Field876s:
          EnumChronList.append(str("No Enumeration"))
        else:
          for Field876 in Field876s:
            enum_chron = Field876.get_subfields('3')
            if not enum_chron:
              EnumChronList.append(str("No Enumeration"))
            else:
              for i in enum_chron:
                EnumChronList.append(str(i))
        csv_out.writerow([LCN, LDR06, LOCN, BranchName, Location, Field863list, Field866list, EnumChronList])
      except KeyError:
            pass

colnamesc = ['LCN', 'LDR06', 'LOCN', 'BranchName', 'Location', 'field863', 'field866', 'field8763']
LHRs = pd.read_csv('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/MultipartMonoProtoLHRs.csv', names=colnamesc, low_memory=False)
column_headers = list(LHRs.columns.values)
print(column_headers)

LHRs = LHRs.astype(str)
LHRs = LHRs.rename(columns={"LDR06": "LHRLDR06"})
LHRs['LOCN'] = LHRs['LOCN'].astype(str)
LHRs['LOCN'] = LHRs['LOCN'].str.strip()
LHRs['LOCN'] = LHRs['LOCN'].str.lstrip('0')

LHRs.head(3)

Bibs.to_sql('Bibs', conn, if_exists='replace', index = False)

LHRs.to_sql('LHRs', conn, if_exists='replace', index = False)

LHRs = pd.read_sql("""SELECT [LOCN], [LCN], [BranchName], [Location], [field8763], [field866], [field863] FROM LHRs WHERE [LHRLDR06] Like 'v' AND [Location] Not Like '%Micro%'""", conn)

LHRs.to_sql('LHRs', conn, if_exists='replace', index = False)

mpm = pd.read_sql("""SELECT DISTINCT(Bibs.[OCN]) AS oclc, LHRs.[LCN] AS local_id, [field00828] AS govdoc, [field8763] AS enum_chron
FROM Bibs INNER JOIN LHRs ON Bibs.[OCN]=LHRs.[LOCN] WHERE (([LDR06] In ('a', 't', 'c', 'd') AND [field00823] Not In ('o', 's', 'q', 'a', 'b')) OR ([LDR06] In ('e', 'f', 'k') AND [field00829] Not In ('o', 's', 'q', 'a', 'b'))) AND [LDR07] Like 'm' AND [field533] Not Like '%Micro%'""", conn)

mpm.sample(10)

len(mpm)

mpm['enum_chron'] = mpm['enum_chron'].astype(str)

mpm['enum_chron'] = mpm['enum_chron'].str.split(',')

mpm = mpm.explode('enum_chron')

mpm['enum_chron'] = mpm['enum_chron'].str.replace('[', '')

mpm['enum_chron'] = mpm['enum_chron'].str.replace(']', '')

mpm['enum_chron'] = mpm['enum_chron'].str.replace("'", '')

mpm['govdoc'] = mpm['govdoc'].replace(['f'], '1')

print(mpm['govdoc'].unique())

mpm['govdoc'] = mpm['govdoc'].replace([' ', 's', 'i', 'l', 'o', 'm', 'c', 'z', 'u', 'a', 'h'], '0')

print(mpm)

mpm['oclc'] = mpm['oclc'].str.replace('\\','')

mpm.to_csv('/content/drive/My Drive/Data Services/HathiTrustHoldingsLoad/2025/SeptVersion/wvu_mpm_full_202509.tsv', sep = '\t', index=False)